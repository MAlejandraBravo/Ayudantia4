{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "El **Transfer Learning** es un paradigma que utiliza el conocimiento de un *dominio de origen* (source) para beneficiar a un *dominio de destino* (target) relacionado. Proporciona una alternativa para utilizar un modelo previamente aprendido en nuevos dominios, en lugar de construir un modelo completamente nuevo.\n",
        "\n",
        "Existen diferentes categorías de Transfer Learning, siendo el *\"fine-tuning\"* una de las más populares. En este enfoque, se utiliza un modelo preentrenado, comúnmente entrenado con datos genéricos (por ejemplo, una CNN entrenada con el conjunto de datos ImageNet), que luego se ajusta para resolver un problema específico en el dominio de destino. Este enfoque aborda la dificultad de entrenar un modelo completamente desde cero, especialmente cuando el conjunto de datos etiquetados es pequeño, lo que complica el entrenamiento de arquitecturas con un gran número de parámetros, como las CNN.\n",
        "\n",
        "Para aprovechar el conocimiento de redes pre-entrenadas basadas en arquitecturas de CNN, hay dos enfoques principales:\n",
        "\n",
        "* **Full Fine-Tuning:** se entrenan todas las capas de la arquitectura preentrenada, incluidas las capas convolucionales y la parte *fully connected*.\n",
        "\n",
        "* **Feature extraction:** En este enfoque, solo se utilizan las características aprendidas por el modelo preentrenado, lo que implica congelar los parámetros del backbone preentrenado (es decir, estos no se actualizan). Para lograrlo, se congelan las capas convolucionales (**Freezing Layers**) durante el entrenamiento, y únicamente se entrena la parte *fully connected*.\n",
        "\n",
        "* **Fine-tuning parcial:** solo se entrenan algunas capas convolucionales, junto con la parte *fully connected*."
      ],
      "metadata": {
        "id": "4QqVMjon56Zs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction using pre-trained CNNs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wFeK4p65txs4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbBMEuw7f4ZV",
        "outputId": "26cd1ca2-b0f6-4c68-87e9-94b5788a9a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnjURJjTgS8R",
        "outputId": "7c981c63-003c-4862-b6c1-1e7faf60d53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchmetrics\n",
        "import time\n",
        "from torchinfo import summary\n",
        "import torchvision\n",
        "from torchvision.models import list_models\n",
        "import timm\n",
        "import os\n",
        "import torchinfo\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqaqnYfBgTAj",
        "outputId": "b5e512b6-0ee6-43fa-ed34-74c89dd37b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transforms:\n",
        "    def __init__(self, transform: A.Compose):\n",
        "        self.transform = transform\n",
        "\n",
        "    def __call__(self, image):\n",
        "        image = np.array(image)\n",
        "        return self.transform(image=image)[\"image\"]\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [A.Resize(256, 256), A.ToFloat(), ToTensorV2()]\n",
        ")\n",
        "validation_transforms = A.Compose(\n",
        "    [A.Resize(256, 256), A.ToFloat(), ToTensorV2()]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ynY21e-GgTDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7QoeTC6gTGU",
        "outputId": "5dc02385-f57d-4ea2-8c00-c071ec7f3aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageFolder(\n",
        "    \"drive/MyDrive/monkey/training\",\n",
        "    transform=Transforms(train_transforms),\n",
        ")\n",
        "validation_data = ImageFolder(\n",
        "    \"drive/MyDrive/monkey/validation\",\n",
        "    transform=Transforms(validation_transforms),\n",
        ")\n",
        "\n",
        "print(f\"Elementos en Entrenamiento: {len(train_data)}\")\n",
        "print(f\"Elementos en Validación: {len(validation_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax5SK_w3gTIt",
        "outputId": "4c525411-e1e6-42b4-b604-f7367e73bb6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en Entrenamiento: 1097\n",
            "Elementos en Validación: 272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Una pequeña muestra de datos de test a partir de los datos de validación\n",
        "from torch.utils.data import random_split\n",
        "# Calcular el tamaño del 20% del conjunto de validación\n",
        "test_size = int(0.2 * len(validation_data))\n",
        "validation_size = len(validation_data) - test_size\n",
        "\n",
        "# Dividir el conjunto de validación en validación (80%) y prueba (20%)\n",
        "validation_data, test_data = random_split(validation_data, [validation_size, test_size])\n",
        "\n",
        "# Imprimir el tamaño de cada subconjunto\n",
        "print(f\"Elementos en Entrenamiento: {len(train_data)}\")\n",
        "print(f\"Elementos en Validación: {len(validation_data)}\")\n",
        "print(f\"Elementos en Prueba: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQdYjsZdgdUO",
        "outputId": "4b9a141c-e545-4594-8995-f949bce46707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elementos en Entrenamiento: 1097\n",
            "Elementos en Validación: 218\n",
            "Elementos en Prueba: 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "j9kvws47gdYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG16**\n",
        "\n",
        "![Descripción de la imagen](https://drive.google.com/uc?export=view&id=167YiD4u4KQ52oZ135DwS_Oif6pIVL0Nb)\n"
      ],
      "metadata": {
        "id": "4RLAkH4BC5eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16FeatureExtractor(nn.Module):\n",
        "    def __init__(self, num_classes=10, frozen=True):\n",
        "        super(VGG16FeatureExtractor, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # Cargar VGG16 preentrenado de timm\n",
        "        self.backbone = timm.create_model('vgg16', pretrained=True, num_classes=0)\n",
        "        if frozen:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.LazyLinear(512), #el tamaño de entrada se determina automáticamente\n",
        "            nn.Linear(512, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xe9D8f2Dgdbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar el modelo\n",
        "model = VGG16FeatureExtractor(num_classes=10)\n",
        "torchinfo.summary(model,input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1lu99nZiguY",
        "outputId": "8bf358f5-069a-4eb1-a473-b32a24f2f733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "VGG16FeatureExtractor                         [1, 10]                   --\n",
              "├─VGG: 1-1                                    [1, 4096]                 --\n",
              "│    └─Sequential: 2-1                        [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-1                       [1, 64, 224, 224]         (1,792)\n",
              "│    │    └─ReLU: 3-2                         [1, 64, 224, 224]         --\n",
              "│    │    └─Conv2d: 3-3                       [1, 64, 224, 224]         (36,928)\n",
              "│    │    └─ReLU: 3-4                         [1, 64, 224, 224]         --\n",
              "│    │    └─MaxPool2d: 3-5                    [1, 64, 112, 112]         --\n",
              "│    │    └─Conv2d: 3-6                       [1, 128, 112, 112]        (73,856)\n",
              "│    │    └─ReLU: 3-7                         [1, 128, 112, 112]        --\n",
              "│    │    └─Conv2d: 3-8                       [1, 128, 112, 112]        (147,584)\n",
              "│    │    └─ReLU: 3-9                         [1, 128, 112, 112]        --\n",
              "│    │    └─MaxPool2d: 3-10                   [1, 128, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-11                      [1, 256, 56, 56]          (295,168)\n",
              "│    │    └─ReLU: 3-12                        [1, 256, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-13                      [1, 256, 56, 56]          (590,080)\n",
              "│    │    └─ReLU: 3-14                        [1, 256, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-15                      [1, 256, 56, 56]          (590,080)\n",
              "│    │    └─ReLU: 3-16                        [1, 256, 56, 56]          --\n",
              "│    │    └─MaxPool2d: 3-17                   [1, 256, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-18                      [1, 512, 28, 28]          (1,180,160)\n",
              "│    │    └─ReLU: 3-19                        [1, 512, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-20                      [1, 512, 28, 28]          (2,359,808)\n",
              "│    │    └─ReLU: 3-21                        [1, 512, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-22                      [1, 512, 28, 28]          (2,359,808)\n",
              "│    │    └─ReLU: 3-23                        [1, 512, 28, 28]          --\n",
              "│    │    └─MaxPool2d: 3-24                   [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-25                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-26                        [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-27                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-28                        [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-29                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-30                        [1, 512, 14, 14]          --\n",
              "│    │    └─MaxPool2d: 3-31                   [1, 512, 7, 7]            --\n",
              "│    └─ConvMlp: 2-2                           [1, 4096, 1, 1]           --\n",
              "│    │    └─Conv2d: 3-32                      [1, 4096, 1, 1]           (102,764,544)\n",
              "│    │    └─ReLU: 3-33                        [1, 4096, 1, 1]           --\n",
              "│    │    └─Dropout: 3-34                     [1, 4096, 1, 1]           --\n",
              "│    │    └─Conv2d: 3-35                      [1, 4096, 1, 1]           (16,781,312)\n",
              "│    │    └─ReLU: 3-36                        [1, 4096, 1, 1]           --\n",
              "│    └─ClassifierHead: 2-3                    [1, 4096]                 --\n",
              "│    │    └─SelectAdaptivePool2d: 3-37        [1, 4096]                 --\n",
              "│    │    └─Dropout: 3-38                     [1, 4096]                 --\n",
              "│    │    └─Identity: 3-39                    [1, 4096]                 --\n",
              "│    │    └─Identity: 3-40                    [1, 4096]                 --\n",
              "├─Sequential: 1-2                             [1, 10]                   --\n",
              "│    └─Linear: 2-4                            [1, 512]                  2,097,664\n",
              "│    └─Linear: 2-5                            [1, 10]                   5,130\n",
              "===============================================================================================\n",
              "Total params: 136,363,338\n",
              "Trainable params: 2,102,794\n",
              "Non-trainable params: 134,260,544\n",
              "Total mult-adds (G): 15.48\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 108.45\n",
              "Params size (MB): 545.45\n",
              "Estimated Total Size (MB): 654.51\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16Flatten(nn.Module):\n",
        "    def __init__(self, frozen=True):\n",
        "        super(VGG16Flatten, self).__init__()\n",
        "        # Cargar VGG16 preentrenado con la capa de clasificación removida\n",
        "        self.backbone = timm.create_model('vgg16', pretrained=True, num_classes=0)\n",
        "\n",
        "        # Congelar los parámetros si frozen=True\n",
        "        if frozen:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extraer características y aplanarlas\n",
        "        features = self.backbone(x)\n",
        "        #flattened_features = self.flatten(features)\n",
        "        return features"
      ],
      "metadata": {
        "id": "khJXdzBDlSFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = VGG16Flatten()\n",
        "torchinfo.summary(feature_extractor,input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw_oqkyUqk9u",
        "outputId": "198aa36f-11ed-4546-a5ce-f07084ca21ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "VGG16Flatten                                  [1, 4096]                 --\n",
              "├─VGG: 1-1                                    [1, 4096]                 --\n",
              "│    └─Sequential: 2-1                        [1, 512, 7, 7]            --\n",
              "│    │    └─Conv2d: 3-1                       [1, 64, 224, 224]         (1,792)\n",
              "│    │    └─ReLU: 3-2                         [1, 64, 224, 224]         --\n",
              "│    │    └─Conv2d: 3-3                       [1, 64, 224, 224]         (36,928)\n",
              "│    │    └─ReLU: 3-4                         [1, 64, 224, 224]         --\n",
              "│    │    └─MaxPool2d: 3-5                    [1, 64, 112, 112]         --\n",
              "│    │    └─Conv2d: 3-6                       [1, 128, 112, 112]        (73,856)\n",
              "│    │    └─ReLU: 3-7                         [1, 128, 112, 112]        --\n",
              "│    │    └─Conv2d: 3-8                       [1, 128, 112, 112]        (147,584)\n",
              "│    │    └─ReLU: 3-9                         [1, 128, 112, 112]        --\n",
              "│    │    └─MaxPool2d: 3-10                   [1, 128, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-11                      [1, 256, 56, 56]          (295,168)\n",
              "│    │    └─ReLU: 3-12                        [1, 256, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-13                      [1, 256, 56, 56]          (590,080)\n",
              "│    │    └─ReLU: 3-14                        [1, 256, 56, 56]          --\n",
              "│    │    └─Conv2d: 3-15                      [1, 256, 56, 56]          (590,080)\n",
              "│    │    └─ReLU: 3-16                        [1, 256, 56, 56]          --\n",
              "│    │    └─MaxPool2d: 3-17                   [1, 256, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-18                      [1, 512, 28, 28]          (1,180,160)\n",
              "│    │    └─ReLU: 3-19                        [1, 512, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-20                      [1, 512, 28, 28]          (2,359,808)\n",
              "│    │    └─ReLU: 3-21                        [1, 512, 28, 28]          --\n",
              "│    │    └─Conv2d: 3-22                      [1, 512, 28, 28]          (2,359,808)\n",
              "│    │    └─ReLU: 3-23                        [1, 512, 28, 28]          --\n",
              "│    │    └─MaxPool2d: 3-24                   [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-25                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-26                        [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-27                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-28                        [1, 512, 14, 14]          --\n",
              "│    │    └─Conv2d: 3-29                      [1, 512, 14, 14]          (2,359,808)\n",
              "│    │    └─ReLU: 3-30                        [1, 512, 14, 14]          --\n",
              "│    │    └─MaxPool2d: 3-31                   [1, 512, 7, 7]            --\n",
              "│    └─ConvMlp: 2-2                           [1, 4096, 1, 1]           --\n",
              "│    │    └─Conv2d: 3-32                      [1, 4096, 1, 1]           (102,764,544)\n",
              "│    │    └─ReLU: 3-33                        [1, 4096, 1, 1]           --\n",
              "│    │    └─Dropout: 3-34                     [1, 4096, 1, 1]           --\n",
              "│    │    └─Conv2d: 3-35                      [1, 4096, 1, 1]           (16,781,312)\n",
              "│    │    └─ReLU: 3-36                        [1, 4096, 1, 1]           --\n",
              "│    └─ClassifierHead: 2-3                    [1, 4096]                 --\n",
              "│    │    └─SelectAdaptivePool2d: 3-37        [1, 4096]                 --\n",
              "│    │    └─Dropout: 3-38                     [1, 4096]                 --\n",
              "│    │    └─Identity: 3-39                    [1, 4096]                 --\n",
              "│    │    └─Identity: 3-40                    [1, 4096]                 --\n",
              "===============================================================================================\n",
              "Total params: 134,260,544\n",
              "Trainable params: 0\n",
              "Non-trainable params: 134,260,544\n",
              "Total mult-adds (G): 15.48\n",
              "===============================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 108.45\n",
              "Params size (MB): 537.04\n",
              "Estimated Total Size (MB): 646.09\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de extracción de características\n",
        "img = \"drive/MyDrive/monkey/training/n0/n018.jpg\"\n",
        "img = Image.open(img)\n",
        "img = np.array(img)\n",
        "augmented = transforms(image=img)\n",
        "input_tensor = augmented[\"image\"].unsqueeze(0).to(device)\n",
        "features = feature_extractor(input_tensor)\n",
        "print(features.shape)  # Mostrar la forma de las características extraídas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0gUnE5jgniQ",
        "outputId": "13e7b505-0164-49a5-f3e8-15354bb53e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZdVm0HxkdUT",
        "outputId": "4aa6529d-4236-4078-f0db-1a731600a802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.2358, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir las métricas\n",
        "train_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=10, average=\"macro\").to(device)\n",
        "val_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=10, average=\"macro\").to(device)"
      ],
      "metadata": {
        "id": "vZ8-kjaUgnl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(\n",
        "    train_data,\n",
        "    val_data,\n",
        "    model,\n",
        "    training_params,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "):\n",
        "    print(f\"Using device: {device}\")\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=training_params[\"learning_rate\"],\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=training_params[\"batch_size\"],\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_dataloader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=training_params[\"batch_size\"],\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    # Configuración para el early stopping\n",
        "    early_stopping_patience = 10  # Número de épocas sin mejora antes de detener el entrenamiento\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Directorio para guardar los checkpoints\n",
        "    checkpoint_dir = 'checkpoints'\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    for e in range(training_params[\"num_epochs\"]):\n",
        "        start_time = time.time()\n",
        "        train_batch_loss = []\n",
        "        val_batch_loss = []\n",
        "        model.train()\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tr_acc = train_metric(y_hat, y)\n",
        "            train_batch_loss.append(loss.item())\n",
        "\n",
        "        tr_acc = train_metric.compute()\n",
        "        train_epoch_loss = np.mean(train_batch_loss)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_acc = val_metric(y_hat, y)\n",
        "                val_batch_loss.append(loss.item())\n",
        "\n",
        "        val_acc = val_metric.compute()\n",
        "        val_epoch_loss = np.mean(val_batch_loss)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(\n",
        "            f\"Epoch: {e+1}: Time: {elapsed_time:.2f} - Train Loss: {train_epoch_loss:.4f} - Validation Loss: {val_epoch_loss:.4f} - Train F1: {tr_acc:.4f} - Validation F1: {val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        train_loss.append(train_epoch_loss)\n",
        "        val_loss.append(val_epoch_loss)\n",
        "\n",
        "        # Checkpointing\n",
        "        if val_epoch_loss < best_val_loss:\n",
        "          best_val_loss = val_epoch_loss\n",
        "          patience_counter = 0\n",
        "          # Guardar el modelo\n",
        "          checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{e}.pth')\n",
        "          torch.save(model.state_dict(), checkpoint_path)\n",
        "          print(f'Model checkpoint saved at epoch {e}')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f'Early stopping triggered at epoch {e-10}. Best validation loss: {best_val_loss:.4f}')\n",
        "            break\n",
        "\n",
        "    return model, train_loss, val_loss"
      ],
      "metadata": {
        "id": "NHcf9Goignoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de hiperparámetros de entrenamiento\n",
        "training_params = dict(\n",
        "    learning_rate=3e-4,\n",
        "    batch_size=64,\n",
        "    num_epochs=100,\n",
        ")"
      ],
      "metadata": {
        "id": "vqoMStEugnrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo utilizando la función `train_model`\n",
        "ft_vgg16, train_loss, val_loss = train_model(\n",
        "    train_data,\n",
        "    validation_data,\n",
        "    model=model,\n",
        "    training_params=training_params,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I5e43l2gTL0",
        "outputId": "773a81ed-e03b-42ea-d223-03d889c4eecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch: 1: Time: 18.39 - Train Loss: 0.7609 - Validation Loss: 0.2130 - Train F1: 0.7915 - Validation F1: 0.9588\n",
            "Model checkpoint saved at epoch 0\n",
            "Epoch: 2: Time: 19.47 - Train Loss: 0.1312 - Validation Loss: 0.1210 - Train F1: 0.8765 - Validation F1: 0.9607\n",
            "Model checkpoint saved at epoch 1\n",
            "Epoch: 3: Time: 18.65 - Train Loss: 0.0764 - Validation Loss: 0.1044 - Train F1: 0.9126 - Validation F1: 0.9630\n",
            "Model checkpoint saved at epoch 2\n",
            "Epoch: 4: Time: 19.34 - Train Loss: 0.0516 - Validation Loss: 0.1059 - Train F1: 0.9333 - Validation F1: 0.9664\n",
            "Epoch: 5: Time: 17.61 - Train Loss: 0.0317 - Validation Loss: 0.1073 - Train F1: 0.9462 - Validation F1: 0.9647\n",
            "Epoch: 6: Time: 17.99 - Train Loss: 0.0216 - Validation Loss: 0.0919 - Train F1: 0.9552 - Validation F1: 0.9667\n",
            "Model checkpoint saved at epoch 5\n",
            "Epoch: 7: Time: 19.46 - Train Loss: 0.0146 - Validation Loss: 0.0905 - Train F1: 0.9616 - Validation F1: 0.9681\n",
            "Model checkpoint saved at epoch 6\n",
            "Epoch: 8: Time: 19.54 - Train Loss: 0.0113 - Validation Loss: 0.0903 - Train F1: 0.9664 - Validation F1: 0.9692\n",
            "Model checkpoint saved at epoch 7\n",
            "Epoch: 9: Time: 19.85 - Train Loss: 0.0095 - Validation Loss: 0.0916 - Train F1: 0.9701 - Validation F1: 0.9700\n",
            "Epoch: 10: Time: 18.45 - Train Loss: 0.0078 - Validation Loss: 0.0903 - Train F1: 0.9731 - Validation F1: 0.9707\n",
            "Model checkpoint saved at epoch 9\n",
            "Epoch: 11: Time: 19.44 - Train Loss: 0.0069 - Validation Loss: 0.0889 - Train F1: 0.9755 - Validation F1: 0.9713\n",
            "Model checkpoint saved at epoch 10\n",
            "Epoch: 12: Time: 19.43 - Train Loss: 0.0060 - Validation Loss: 0.0904 - Train F1: 0.9776 - Validation F1: 0.9713\n",
            "Epoch: 13: Time: 18.31 - Train Loss: 0.0049 - Validation Loss: 0.0915 - Train F1: 0.9793 - Validation F1: 0.9713\n",
            "Epoch: 14: Time: 18.05 - Train Loss: 0.0044 - Validation Loss: 0.0912 - Train F1: 0.9808 - Validation F1: 0.9714\n",
            "Epoch: 15: Time: 18.24 - Train Loss: 0.0039 - Validation Loss: 0.0916 - Train F1: 0.9820 - Validation F1: 0.9711\n",
            "Epoch: 16: Time: 18.03 - Train Loss: 0.0036 - Validation Loss: 0.0919 - Train F1: 0.9832 - Validation F1: 0.9711\n",
            "Epoch: 17: Time: 18.21 - Train Loss: 0.0033 - Validation Loss: 0.0919 - Train F1: 0.9842 - Validation F1: 0.9712\n",
            "Epoch: 18: Time: 18.07 - Train Loss: 0.0030 - Validation Loss: 0.0927 - Train F1: 0.9850 - Validation F1: 0.9712\n",
            "Epoch: 19: Time: 17.64 - Train Loss: 0.0028 - Validation Loss: 0.0921 - Train F1: 0.9858 - Validation F1: 0.9712\n",
            "Epoch: 20: Time: 17.89 - Train Loss: 0.0025 - Validation Loss: 0.0943 - Train F1: 0.9865 - Validation F1: 0.9713\n",
            "Epoch: 21: Time: 18.29 - Train Loss: 0.0023 - Validation Loss: 0.0944 - Train F1: 0.9872 - Validation F1: 0.9715\n",
            "Early stopping triggered at epoch 10. Best validation loss: 0.0889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una nueva instancia del modelo con los mismos parámetros que el modelo original\n",
        "best_model = VGG16FeatureExtractor(num_classes=10)\n",
        "checkpoint_path = os.path.join('checkpoints', 'checkpoint_epoch_10.pth')\n",
        "best_model.load_state_dict(torch.load(checkpoint_path,weights_only=True))\n",
        "best_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvxu-QfigTOm",
        "outputId": "2c2aae8d-d031-4166-e031-c4d4534ff61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16FeatureExtractor(\n",
              "  (backbone): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (pre_logits): ConvMlp(\n",
              "      (fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "    (head): ClassifierHead(\n",
              "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "      (drop): Dropout(p=0.0, inplace=False)\n",
              "      (fc): Identity()\n",
              "      (flatten): Identity()\n",
              "    )\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): LazyLinear(in_features=0, out_features=512, bias=True)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(model_input, data_eva):\n",
        "    # Cambiar el modelo al modo de evaluación\n",
        "    model_input.eval()\n",
        "\n",
        "    # Inicializar el cálculo de F1-score\n",
        "    f1_metric = torchmetrics.F1Score(task=\"multiclass\", num_classes=10, average=\"macro\").to(device)\n",
        "    data_eva = DataLoader(data_eva,batch_size=training_params[\"batch_size\"],shuffle=False,num_workers=2,pin_memory=True,)\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "    # Desactivar el cálculo de gradientes ya que no necesitamos backpropagation\n",
        "    with torch.no_grad():\n",
        "        test_loss = []\n",
        "        total_samples = 0\n",
        "\n",
        "        # Iterar sobre el conjunto de datos de test\n",
        "        for batch in data_eva:\n",
        "            # Mover los datos al dispositivo adecuado (CPU o GPU)\n",
        "            features, target = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "            # Hacer predicciones con el modelo\n",
        "            output = model_input(features)\n",
        "            loss = criterion(output, target.squeeze())  # Asegurarse de que las dimensiones coincidan\n",
        "            test_loss.append(loss.item())\n",
        "\n",
        "            # Convertir las predicciones a clases con la probabilidad máxima\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "\n",
        "            # Actualizar el cálculo del F1-score\n",
        "            f1_metric.update(preds, target)\n",
        "\n",
        "    # Calcular el F1-score final\n",
        "    f1_score = f1_metric.compute().item()\n",
        "\n",
        "    print(f'F1-score: {f1_score:.5f}')"
      ],
      "metadata": {
        "id": "T1kkpHYhisOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing(model,test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01a53LkzisSG",
        "outputId": "f718b9ab-b962-439d-908b-a3c033cdd711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score: 0.95980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ploting(train_loss,val_loss):\n",
        "  plt.plot(range(len(train_loss)),train_loss,color='blue',label='Train')\n",
        "  plt.plot(range(len(val_loss)), val_loss,color='red',label='Val')\n",
        "  plt.legend(title = \"Loss\")"
      ],
      "metadata": {
        "id": "xuNu3CLZisVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ploting(train_loss,val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "QKX-PUhCi06_",
        "outputId": "d230a99e-8d2c-47ac-df41-8ec6a2de065d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0In8Di-i0-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hudPRjT1i1CT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhckYTPhgTRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}